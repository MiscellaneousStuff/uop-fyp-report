\section{Data Augmentation via EMG Synthesis}

One approach for improving the performance of any machine learning model
is to synthesize more data. This is particularly useful if the original
dataset is small and there are methods to synthesize more data.

\subsection{Related Work}

Previous approaches have used various deep learning techniques to synthesize
more EMG data to train EMG deep learning models. One approach
(\cite{gpt_2_emg_synth}) uses a GPT-2 (\cite{gpt_2_original}) like model
to synthesis EMG signals for simple action recognition such as grasp and
release (actions common to robotic prosthetics and manipulators). The inclusion
of synthesized EMG data during the training process improved the overall
gesture recognition accuracy from 68.29\% to 89.5\%.

Another related paper from the same author experiments with LSTM and GPT-2
models for synthesizing more speech for a speaker recogntion task. The
best model found by the authors for this task was a
3-layer, 128 hidden dimension LSTM network (\cite{speech_synth_lstm}).

\subsection{Summary}

In summary, my hypothesis was disproved.
My initial hypothesis was that it was possible to simply reverse the
transduction network, which was introduced in the Digital Voicing paper
for transcribing from EMG features into speech features, but instead
reverse the features.
From my findings I found that this wasn't true because the low level 
features of the EMG data are difficult for the LSTM network to correctly reproduce.

In hindsight my approach could have been improved by being more selective in
the early stages. I could have determined which electrode contributed the most
in the transduction task, and then tried to just synthesise the signals for that 
particular channel and then tried to synthesise an increasing number of electrode channels.