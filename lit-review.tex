\iffalse

Mu-Law compression:
- compresses audio signal into discrete bins whilst preserving dynamic range

Current sEMG Silent Speech Text Classification Research:
- https://dspace.mit.edu/bitstream/handle/1721.1/123121/1128187233-MIT.pdf?sequence=1&isAllowed=y

\fi

\chapter{Literature Review} \label{chap:lit-review}

\section{Silent Speech Interfaces for Speech Restoration: A Review}


\section{Proposed Directions for Research}

\subsection{Text Classification}

\subsection{Data Augmentation}

It might be possible to use GANs (Generative Adversarial Networks) or
VAEs (Variational Auto Encoders) to create a model which can generate
more data samples.

\subsection{Improving Existing Model}

Use RL-Learning to find a model which can outperform the original model
(problem is small dataset size which means that the benefits of using RL
to create a model might not be as applicable to this problem).

Use CapsNet on top of the CNNs to improve the generalisability of the
detected EEG features (there are papers which show that these are
feasible).

\section{Connectionist Temporal Classification (CTC)}

For any speech recognition task, a model must know the alignment
between the input (e.g. audio, EMG features, etc.) and the target
transcription. On the surface, this makes training any speech
recognition model difficult.

Without having the alignments between the input and the transcription,
simpler approaches aren't available to us, such as mapping a single
character to a fixed number of inputs. This is because people's rates
of speech vary, regardless of the input modality (e.g. audio, EMG features,
etc). Another option is to hand-label the alignments between the input
and the text transcriptions. This would produce a performant model, however,
hand-labeling the alignments is time consuming, especially for larger datasets.

Connectionist Temporal Classification (CTC) is a method to train a model
without knowing the alignment between the input and the output and is especially
well suited to labeled datasets such as speech recognition.