\chapter{Research Overview} \label{chap:research-overview}

This section details the research which was conducted during this project
at a high level. The individual approaches futher on contain the datasets,
experimental conditions, assumptions, related work and evaluation metrics
along with justification for each individual approach.

\section{Informal Research Goals}

One central idea to the research experiments conducted in this project
is reproducibilty. Every single experiment for the silent speech
recognition fine tuning was run with the same random seed as was the
experiments for the EMG synthesize.

Random seeds are important for machine learning projects because
they are used to initialise the weights of neural networks. Different
random seeds can drastically change the performance of a neural network,
with some authors finding that the standard deviation of a model's performance
can vary by as much as 72\% (\cite{random_seed_variance}).
They are also used to determine
the order in which training datasets
are shuffled and arranged into mini-batches for training and many
other countless implementation details.

The following random seeds were used during research and were used
to intialise the random seed values of the NumPy,
PyTorch (\cite{pytorch}) and default Python random number generator.

{\small\begin{center}
    \captionof{table}{Random Seed Values per Approach}
    \begin{tabular} {  l  c  c  }
    \hline
    Approach & Random Seed Value \\
    \hline
    EMG Synthesis & 1 \\
    ASR Fine Tuning & 7 \\
    \end{tabular}
\end{center}}

\section{Full List of Research Questions with Hypotheses}

\subsection{Data Augmentation via EMG Synthesis}

Question: How feasible is the synthesis of silent speech EMG signals
as a data augmentation technique for training EMG silent speech systems?

Hypothesis: Training an EMG synthesis model based on a small
EMG dataset will improve the final performance of transduction model

Measurable: Test loss of the final transduction system when trained
with augmented EMG data versus without

Measurable: Visual inspection of the synthesized EMG signals

Measurable: Visual inspection of the predicted mel spectrograms when
trained with augmented EMG data versus without

\subsection{Fine Tuning Speech Recognition on Transducer Predictions }

The basis for this hypothesis comes from my literature review and
experiments conducted during the EMG synthesis experiments. I noticed
how the mel spectrograms from the regular transduction model looked
blurrier, less precise and out of sync with the ground truth models.

From this observation I looked into speech recognition models and
tried to determine if speech recognition models which were trained
on clean datasets suffered drastic accuracy loses when evaluated
on noisy datasets. As it turns out this is true (\cite{DS2_original}).
This line of reasoning is explored further in the ASR fine tuning approach.

Question: Can fine tuning an ASR model on a silent speech
transduction models mel spectrogram predictions improve performance for
text classification? \\

Hypothesis: Fine tuning an ASR model with the predicted
mel spectrograms from a pre-trained silent speech transduction model
can improve inference time and reduce the required training dataset
while maintaining competitive accuracy \\

Measurable: WER of final system compared to SOTA for text classification \\
Measurable: Dataset size required to train the ASR system in hours \\

The end-to-end inference time of the system is not measured in this
approach. The reason for this is because, as the approach removes one
entire component compared to previous approaches, it was determined that
measuring this difference is redundant as the system is guaranteed
to be faster. Measuring this difference will be conducted in future
research.